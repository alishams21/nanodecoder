# GPT Model Configuration
model:
  vocab_size: 50257
  max_context_length: 256 #1024  # Increased for OpenWebText (better context understanding)
  n_embd: 200              # Embedding dimension (divisible by n_head)
  n_head: 4             # Increased attention heads for better representation
  n_blocks: 4            # Increased layers for larger dataset capacity
  drop_rate: 0.1          # Dropout rate
  qkv_bias: false         # Query-key-value bias
  n_exp: 2 #8                # Increased experts for larger dataset diversity
  top_k: 1                # Top k experts (increased for better routing)
  use_noisy_top_k: true   # Use noisy top k
  capacity_factor: 1.5    # Increased capacity factor for larger batches
  bias: false             # Bias
  dropout: 0.2            # Reduced dropout for larger dataset
  flash_self_attention: false # for faster self-attention
  use_switch_tfm_init: true # Use switch transformer-style initialization
  switch_tfm_init_scale: 1.0 # Switch transformer-style initialization scale
  use_switch_tfm_init_experts: true # Use switch transformer-style initialization for experts
  switch_tfm_init_scale_experts: 1.0 # Switch transformer-style initialization scale for experts
  stride: 2 # One in every stride layers are converted to an MoE
  use_moe: false # Use MoE
  use_aux_loss: false # Use auxiliary loss
  use_router_z_loss: false # Use router z loss
  router_use_full_prec: false # Use full precision in the router
  train_capacity: 1.25 # Train capacity
  eval_capacity: 2.0 # Eval capacity
  min_capacity: 4 # Minimum capacity
  aux_loss_weight: 0.001 # Auxiliary loss weight
  router_z_loss_weight: 0.01 # Router z loss weight

device:
  device_type: "cpu"  # Changed to cuda for GPU training
  num_workers: 4
  pin_memory: true
  non_blocking: true
  tf32: true
  cudnn_tf32: true
  cudnn_benchmark: false
  cudnn_deterministic: false
  cudnn_allow_tf32: true
  cudnn_allow_tf32_autotune: true
  cudnn_allow_tf32_autotune_deterministic: false
  cudnn_allow_tf32_autotune_deterministic_deterministic: false
  nproc_per_node: 8  # Number of processes per node for DDP training (use with torchrun --nproc_per_node=N)

# Model Compilation Settings (PyTorch 2.0+)
compile:
  enabled: true  # Enable model compilation for additional speedup
  mode: "default"  # Compilation mode: "default", "reduce-overhead", "max-autotune"
  fullgraph: false  # Whether to compile the full graph
  dynamic: null  # Whether to use dynamic shapes

# Memory Management Settings
memory:
  enable_memory_pool: true     # Enable memory pooling for tensor reuse
  buffer_size: 2             # Increased for larger dataset (4-8 recommended)
  max_pool_size: 4            # Increased maximum pool size for larger model
  enable_prefetching: true     # Enable background batch prefetching
  prefetch_timeout: 10.0       # Increased timeout for larger batches
  memory_monitoring: true     # Enable memory usage monitoring
  auto_optimize: true         # Automatically optimize settings based on hardware

# Training Settings
training:
  learning_rate: 0.0003 #0.0003  # Reduced for larger model and dataset
  num_epochs: 1  # Reduced epochs for large dataset
  batch_size: 4 #8  # Increased batch size for multi-GPU (8 GPUs * 8 batch = 64 effective)
  weight_decay: 0.1
  seed: 123
  max_iters: 1000   #100000  # Increased iterations for OpenWebText dataset
  eval_interval: 100 ##2000  # Evaluate every N iterations
  log_interval: 10  #1000  # Log every N iterations
  eval_iters: 10  # Number of batches per evaluation cycle
  grad_clip: 1.0  # Gradient clipping value
  eval_only: false # Only evaluate the model
  best_val_loss: 1000 # Best validation loss this is for initialisation
  accumulation_steps: 16  # Reduced accumulation for multi-GPU (8 GPUs * 8 batch * 4 acc = 256 effective)
  checkpoint_interval: 5000  # Save checkpoint every N iterations

# Learning Rate Schedule Settings
lr_schedule:
  decay_lr: true  # Enable learning rate decay
  warmup_iters: 2000  # Increased warmup for larger model
  lr_decay_iters: 100000  # Increased decay iterations for longer training
  min_lr: 0.00003  # Lower minimum learning rate for fine-tuning

optimizer:
  weight_decay: 0.01
  learning_rate: 0.0003 #0.0003  # Match training learning rate
  betas: [0.9, 0.95]

# Data Settings
data:
  dataset: "moe_gpt/data/shakespeare"  # Use OpenWebText for full training
  train_ratio: 0.90
  eval_freq: 5
  eval_iter: 1

# HellaSwag Evaluation Settings
hellaswag:
  enabled: true  # Enable HellaSwag evaluation
  data_path: "moe_gpt/data/hellaswag/hellaswag_val.jsonl"  # Path to HellaSwag data
  eval_interval: 10  # Evaluate HellaSwag every N iterations (0 to disable)
  batch_size: 20  # Batch size for HellaSwag evaluation
  max_batches: 30  # Maximum number of batches to evaluate (for quick evaluation during training)
  final_max_batches: 500  # Maximum number of batches for final comprehensive evaluation
  max_examples: 50  # Maximum number of examples to evaluate (0 for all)
  download_data: true  # Automatically download HellaSwag data if not found

# Output Settings
output:
  model_save_path: "moe_gpt_model.pth"
  loss_plot_path: "loss.pdf"
  always_save_checkpoint: true
  checkpoint_path: "moe_gpt/checkpoints"

# Wandb Logging Settings
wandb:
  enabled: true
  project: "moe-cpu-run"
  run_name: "moe-cpu-run"
  log_interval: 1

run_type: "normal" # "normal" or "resume"